<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="Homepage of KleinLab">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>KleinLab - Homepage</title>

  <link href="./libs/bootstrap-3.4.1/css/bootstrap.css" rel="stylesheet">
  <link href="./libs/fontawesome-6.2.0/css/all.min.css" rel="stylesheet">
  <link href="style.css" rel="stylesheet">


  <link href='https://fonts.googleapis.com/css?family=Didact Gothic' rel='stylesheet'>
  <style>
  body {
   font-family: 'Didact Gothic';
  }
  </style>

<link rel="icon" href="images/logo_light_wo_frame.png">

</head>
<body data-spy="scroll" data-target="#myScrollspy" data-offset="80">

	<a href="#" id="scrollbutton" class="hidden-md hidden-lg hidden-xl" style="display: none;"><span></span></a>

<div class="container">
	
<h2 style="color:#164194;">KleinLab - Uncertainty Quantification and Statistical Learning</h2>

  <nav class="navbar navbar-light">	  
	<ul class="nav navbar-nav mr-auto">
		<li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
		<li class="nav-item"><a class="nav-link"href="news.html">News</a></li>
		<li class="nav-item"><a class="nav-link" href="team.html">Team</a></li>
		<li class="nav-item"><a class="nav-link" href="research.html">Research</a></li>
		<li class="nav-item active"><a class="nav-link" href="publications.html">Publications</a></li>
		<li class="nav-item"><a class="nav-link" href="teaching.html">Teaching</a></li>
		<li class="nav-item"><a class="nav-link" href="jobs.html">Jobs</a></li>
		<li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
	</ul>
  </nav>

		
<!-- ------------------------------------------------------------------------------------------------------------------------------------ -->
<!-- ------------------------------------------------------------------------------------------------------------------------------------ -->
<!-- ------------------------------------------------------------------------------------------------------------------------------------ -->
<!-- ------------------------------------------------------------------------------------------------------------------------------------ -->

			<!-- Publications -->
			<section id="publications" style="font-size:medium;">
				<h2>Publications <span class="fa fa-book" aria-hidden="true" style="float:left;padding-right:15px;padding-top:6px;font-size: 75%;"></span></h2>
				<p>
					See the <a href="https://scholar.google.de/citations?user=upS2UTIAAAAJ" target="_blank">Google Scholar page of Prof. Klein</a> for a complete and up-to-date list, below some key publications are listed.
					For a complete list of publications, please refer to the following subpages:
				</p>

				<div class="row" style="margin-left: 15px;">
					<div class="column">
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/methodology.html" style="font-size: large;">Peer-Reviewed Journals (Methodology)</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/applications.html" style="font-size: large;">Peer-Reviewed Journals (Applications)</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/books.html" style="font-size: large;">Books & Book Chapters</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/editorials.html" style="font-size: large;">Editorials</a>
							</div>
						</div>

					</div>

					<div class="column">
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/conferences.html" style="font-size: large;">Peer-Reviewed Conferences & Workshops</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/supplementary.html" style="font-size: large;">Supplementary Materials</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/software.html" style="font-size: large;">Software</a>
							</div>
						</div>
		
						<br>
		
						<div class="row">
							<div class="column2" style="width: 2%;">
								<span class="fa fa-folder-open icon"></span>
							</div>
							<div class="column2" style="margin-left: 15px;">
								<a href="subpages_pubs/working_papers.html" style="font-size: large;">Working Papers</a>
							</div>
						</div>

					</div>


				</div>

				


				



				<br>

				<h3>Selected Publications</h3>
				
					<ul class="fa-ul list-group" style="margin-left:25px">
						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>bamlss: Bayesian Additive Models for Location, Scale, and Shape (and beyond) <span class="label label-info"><a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2023.2191820" target="_blank">pdf</a></span></h4>
										M. Carlan, T. Kneib and N. Klein<br>
										<i>To appear in Journal of the American Statistical Association</i>, 2023
									</div>
									<p style="text-align: justify"><u>Abstract:</u> Recent developments in statistical regression methodology shift away from pure mean regression toward distributional regression models. One important strand thereof is that of conditional transformation models (CTMs). CTMs infer the entire conditional distribution directly by applying a transformation function to the response conditionally on a set of covariates toward a simple log-concave reference distribution. Thereby, CTMs allow not only variance, kurtosis or skewness but the complete conditional distribution to depend on the explanatory variables. We propose a Bayesian notion of conditional transformation models (BCTMs) focusing on exactly observed continuous responses, but also incorporating extensions to randomly censored and discrete responses. Rather than relying on Bernstein polynomials that have been considered in likelihood-based CTMs, we implement a spline-based parameterization for monotonic effects that are supplemented with smoothness priors. Furthermore, we are able to benefit from the Bayesian paradigm via easily obtainable credible intervals and other quantities without relying on large sample approximations. A simulation study demonstrates the competitiveness of our approach against its likelihood-based counterpart but also Bayesian additive models of location, scale and shape and Bayesian quantile regression. Two applications illustrate the versatility of BCTMs in problems involving real world data, again including the comparison with various types of competitors. Supplementary materials for this article are available online.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/BCTM.png" alt="BCTM" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Bayesian conditional transformation models <span class="label label-info"><a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2023.2191820" target="_blank">pdf</a></span></h4>
										M. Carlan, T. Kneib and N. Klein<br>
										<i>To appear in Journal of the American Statistical Association</i>, 2023
									</div>
									<p style="text-align: justify"><u>Abstract:</u> Recent developments in statistical regression methodology shift away from pure mean regression toward distributional regression models. One important strand thereof is that of conditional transformation models (CTMs). CTMs infer the entire conditional distribution directly by applying a transformation function to the response conditionally on a set of covariates toward a simple log-concave reference distribution. Thereby, CTMs allow not only variance, kurtosis or skewness but the complete conditional distribution to depend on the explanatory variables. We propose a Bayesian notion of conditional transformation models (BCTMs) focusing on exactly observed continuous responses, but also incorporating extensions to randomly censored and discrete responses. Rather than relying on Bernstein polynomials that have been considered in likelihood-based CTMs, we implement a spline-based parameterization for monotonic effects that are supplemented with smoothness priors. Furthermore, we are able to benefit from the Bayesian paradigm via easily obtainable credible intervals and other quantities without relying on large sample approximations. A simulation study demonstrates the competitiveness of our approach against its likelihood-based counterpart but also Bayesian additive models of location, scale and shape and Bayesian quantile regression. Two applications illustrate the versatility of BCTMs in problems involving real world data, again including the comparison with various types of competitors. Supplementary materials for this article are available online.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/BCTM.png" alt="BCTM" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Bayesian Generalized Additive Models for Location, Scale and Shape for Zero-Inflated and Overdispersed Count Data <span class="label label-info"><a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2014.912955" target="_blank">pdf</a></span></h4>
										N. Klein, T. Kneib and S. Lang<br>
										<i>Journal of the American Statistical Association, 110(509), 405-419</i>, 2015
									</div>
									<p style="text-align: justify"><u>Abstract:</u> Frequent problems in applied research preventing the application of the classical Poisson log-linear model for analyzing count data include overdispersion, an excess of zeros compared to the Poisson distribution, correlated responses, as well as complex predictor structures comprising nonlinear effects of continuous covariates, interactions or spatial effects. We propose a general class of Bayesian generalized additive models for zero-inflated and overdispersed count data within the framework of generalized additive models for location, scale, and shape where semiparametric predictors can be specified for several parameters of a count data distribution. As standard options for applied work we consider the zero-inflated Poisson, the negative binomial and the zero-inflated negative binomial distribution. The additive predictor specifications rely on basis function approximations for the different types of effects in combination with Gaussian smoothness priors. We develop Bayesian inference based on Markov chain Monte Carlo simulation techniques where suitable proposal densities are constructed based on iteratively weighted least squares approximations to the full conditionals. To ensure practicability of the inference, we consider theoretical properties like the involved question whether the joint posterior is proper. The proposed approach is evaluated in simulation studies and applied to count data arising from patent citations and claim frequencies in car insurances. For the comparison of models with respect to the distribution, we consider quantile residuals as an effective graphical device and scoring rules that allow us to quantify the predictive ability of the models. The deviance information criterion is used to select appropriate predictor specifications once a response distribution has been chosen. Supplementary materials for this article are available online.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/BayesAdditiveScaleShape.png" alt="Bayesian Generalized Additive Models for Location, Scale and Shape for Zero-Inflated and Overdispersed Count Data" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>	

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Bayesian Inference for Regression Copulas <span class="label label-info"><a href="https://arxiv.org/abs/1907.04529" target="_blank">pdf</a></span></h4>
										M. S. Smith and N. Klein<br>
										<i>Journal of Business and Economic Statistics, 39(3), 712-728</i>, 2021
									</div>
									<p style="text-align: justify"><u>Abstract:</u> We propose a new semi-parametric distributional regression smoother that is based on a copula decomposition of the joint distribution of the vector of response values. The copula is high-dimensional and constructed by inversion of a pseudo regression, where the conditional mean and variance are semi-parametric functions of covariates modeled using regularized basis functions. By integrating out the basis coefficients, an implicit copula process on the covariate space is obtained, which we call a `regression copula'. We combine this with a non-parametric margin to define a copula model, where the entire distribution - including the mean and variance - of the response is a smooth semi-parametric function of the covariates. The copula is estimated using both Hamiltonian Monte Carlo and variational Bayes; the latter of which is scalable to high dimensions. Using real data examples and a simulation study we illustrate the efficacy of these estimators and the copula model. In a substantive example, we estimate the distribution of half-hourly electricity spot prices as a function of demand and two time covariates using radial bases and horseshoe regularization. The copula model produces distributional estimates that are locally adaptive with respect to the covariates, and predictions that are more accurate than those from benchmark models.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/BayesInfRegressionCopulas.png" alt="Bayesian Inference for Regression Copulas" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Informed priors for knowledge integration in trajectory prediction <span class="label label-info"><a href="https://arxiv.org/abs/1907.04529" target="_blank">pdf</a></span></h4>
										C. Schlauch, N. Klein and C. Wirth<br>
										<i>ECML/PKDD 2023 </i>, 2023
									</div>
									<p style="text-align: justify"><u>Abstract:</u> We </p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/BayesInfRegressionCopulas.png" alt="Bayesian Inference for Regression Copulas" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Marginally calibrated response distributions for end-to-end learning in autonomous driving <span class="label label-info"><a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-17/issue-2/Marginally-calibrated-response-distributions-for-end-to-end-learning-in/10.1214/22-AOAS1693.short" target="_blank">pdf</a></span></h4>
										C. Hoffmann and N. Klein<br>
										<i>Annals of Applied Statistics, 17(2), 1740-1763</i>, 2023
									</div>
									<p style="text-align: justify"><u>Abstract:</u> End-to-end learners for autonomous driving are deep neural networks that predict the instantaneous steering angle directly from images of the street ahead. These learners must provide reliable uncertainty estimates for their predictions in order to meet safety requirements and to initiate a switch to manual control in areas of high uncertainty. However, end-to-end learners typically only deliver point predictions, since distributional predictions are associated with large increases in training time or additional computational resources during prediction. To address this shortcoming, we investigate efficient and scalable approximate inference for the deep distributional model of Klein, Nott and Smith (J. Comput. Graph. Statist. 30 (2021) 467–483) in order to quantify uncertainty for the predictions of end-to-end learners. A special merit of this model, which we refer to as implicit copula neural linear model (IC-NLM), is that it produces densities for the steering angle that are marginally calibrated, that is, the average of the estimated densities equals the empirical distribution of steering angles. To ensure the scalability to large n regimes, we develop efficient estimation based on variational inference as a fast alternative to computationally intensive, exact inference via Hamiltonian Monte Carlo. We demonstrate the accuracy and speed of the variational approach on two end-to-end learners trained for highway driving using the comma2k19 dataset. The IC-NLM is competitive with other established uncertainty quantification methods for end-to-end learning in terms of nonprobabilistic predictive performance and outperforms them in terms of marginal calibration for in-distribution prediction. Our proposed approach also allows the identification of overconfident learners and contributes to the explainability of black-box end-to-end learners by using the predictive densities to understand which steering actions the learner sees as valid.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/EndToEndAutonomousDriving.png" alt="Marginally calibrated response distributions for end-to-end learning in autonomous driving" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>	

						<br>


						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Semi-Structured Distributional Regression <span class="label label-info"><a href="https://www.tandfonline.com/doi/abs/10.1080/00031305.2022.2164054?journalCode=utas20" target="_blank">pdf</a></span></h4>
										D. Rügamer, C. Kolb and N. Klein<br>
										<i>To appear in The American Statistician</i>, 2023									
									</div>
									<p style="text-align: justify"><u>Abstract:</u> Combining additive models and neural networks allows to broaden the scope of statistical regression and extend deep learning-based approaches by interpretable structured additive predictors at the same time. Existing attempts uniting the two modeling approaches are, however, limited to very specific combinations and, more importantly, involve an identifiability issue. As a consequence, interpretability and stable estimation are typically lost. We propose a general framework to combine structured regression models and deep neural networks into a unifying network architecture. To overcome the inherent identifiability issues between different model parts, we construct an orthogonalization cell that projects the deep neural network into the orthogonal complement of the statistical model predictor. This enables proper estimation of structured model parts and thereby interpretability. We demonstrate the framework’s efficacy in numerical experiments and illustrate its special merits in benchmarks and real-world applications.</p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/SemiStructuredDistributionalRegression.png" alt="Semi-Structured Distributional Regression" style="width: 70%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>	

						<br>

						<li class="list-group-item">
							<div class="row">
								<div class="column2" style="width: 2%;">
									<span class="fa-li fa fa-check-square icon"></span>
								</div>

								<div class="column2" style="width: 50%;">
									<div class="content">
										<h4>Variational inference and sparsity in high dimensional deep Gaussian mixture models <span class="label label-info"><a href="https://arxiv.org/abs/1907.04529" target="_blank">pdf</a></span></h4>
										L. Kock, N. Klein and D. J. Nott<br>
										<i>Statistics and Computing</i>, 2022
									</div>
									<p style="text-align: justify"><u>Abstract:</u> We </p>
								</div>

								<div class="column2" style="width: 48%; margin-left: 10px; display: flex; align-items: center; justify-content: center;">
									<img src="images/key_pubs/VI_DeepGaussianMixture.png" alt="" style="width: 100%; display: block; margin-left: auto; margin-right: auto;">
								</div>

							</div>
						</li>

					</ul>
			</div>
		</section>		

		
			


			<!-- Imprint and data protection -->
			<div style="display: inline-block; text-align: right; width: 100%; margin-top: 15px;">
				<a href="https://www.uaruhr.de/impressum/index.html.en">Imprint</a> / <a href="https://www.uaruhr.de/impressum/datenschutz.html.en">Data Protection</a>
			</div>
			
		</div>

				
	</div>
		
	
  </div>
</div>

	<!-- jquery -->
	<script src="./libs/jquery-3.6.1.min.js"></script>
	
	<!-- boostrap -->
	<script src="./libs/bootstrap-3.4.1/js/bootstrap.min.js"></script>

	<!-- Functionality for popover of buttons -->
	<script>
		$(document).ready(function(){
			$('[data-toggle="popover"]').popover(); 
		});
	</script>

	<!-- Functionality for scroll-up button -->
	<script>
	$(document).ready(function(){ 
		if ($(this).scrollTop() > 100) {
			$('#scrollbutton').fadeIn();
		}
		$(window).scroll(function(){ 
			if ($(this).scrollTop() > 100) { 
				$('#scrollbutton').fadeIn();
			} else { 
				$('#scrollbutton').fadeOut(); 
			}
		});
		$('#scrollbutton').click(function(){ 
			$("html, body").animate({ scrollTop: 0 }, 300); 
			return false; 
		}); 
	});
	</script>
	
</body>

</html>
